# ---
这是一个突发奇想的项目，2025年统计建模公示了所有参赛的题目，学校，姓名，编号等。于是突发奇想对参赛题目数据进行挖掘
# 文本挖掘脚本说明

## 脚本简介
本项目中的 `文本挖掘.py` 脚本用于对论文题目进行文本挖掘分析，自动提取关键词、算法模型，统计其出现频率，并进行聚类与可视化，帮助用户快速了解论文题目中的研究热点和方法分布。

## 主要功能
1. **读取Excel数据**：自动读取包含论文题目的Excel文件。
2. **分词与停用词过滤**：利用jieba分词，并结合自定义停用词表，提取有效关键词。
3. **关键词词云**：生成论文题目关键词的词云图。
4. **算法模型提取与统计**：自动识别题目中涉及的常见机器学习、深度学习、NLP等算法模型，并统计出现频率。
5. **算法类别分布可视化**：以条形图和饼图展示算法模型及其类别的分布。
6. **TF-IDF向量化与KMeans聚类**：对题目进行TF-IDF向量化，并用KMeans进行聚类分析。

## 数据处理流程
- 读取Excel文件，提取“论文题目”列。
- 使用jieba分词，结合自定义停用词，得到高质量分词结果。
- 统计高频词并生成词云。
- 通过内置算法模型词典，自动识别题目中涉及的算法模型。
- 统计各算法模型及其类别的出现频率。
- 使用TF-IDF对题目进行向量化，KMeans聚类分析。
- 可视化聚类和统计结果。

## 关键依赖库
- pandas
- jieba
- wordcloud
- matplotlib
- scikit-learn (sklearn)
- numpy

## 使用方法
1. **准备数据**：将包含“论文题目”列的Excel文件放在脚本指定路径（可在代码中修改）。
2. **安装依赖**：

   pip install pandas jieba wordcloud matplotlib scikit-learn numpy

3. **运行脚本**：

   python 文本挖掘.py
   
4. **查看结果**：运行后会弹出词云、条形图、饼图等可视化窗口。

## 注意事项
- Excel文件路径需与脚本中 `file_path` 变量一致，或自行修改为实际路径。
- 需保证有“论文题目”这一列，且内容为文本。
- 若运行时报字体缺失错误，请下载并放置 `simhei.ttf` 字体文件于脚本同目录。
- 若数据量较大，聚类和可视化可能耗时较长。

## 适用场景
- 竞赛论文题目分析




